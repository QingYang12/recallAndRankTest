## 召回（Recall）与排序（Ranking）概念对比

### 总体对比表

| **维度**       | **召回（Recall）**           | **排序（Ranking / CTR）**          |
|----------------|------------------------------|------------------------------------|
| **输入规模**   | 1 亿+ 全量物品               | 几百 ~ 几千候选                     |
| **输出规模**   | 几百 ~ 几千                  | Top 几十（最终曝光）               |
| **核心目标**   | 覆盖兴趣、保证相关性         | 精准预估、最大化业务指标           |
| **典型模型**   | ItemCF, 双塔 DNN             | DeepFM, DIN, Wide&Deep 等          |
| **特征使用**   | 简单、稀疏                   | 复杂、交叉、包含实时特征           |
| **是否用 CTR** | ❌ 一般不用                  | ✅ 核心就是 CTR / 转化率 预估      |

---

## 整体推荐流程示例（以短视频推荐为例）

```text
全量视频库（1亿+）
        ↓
[召回阶段] → 多路召回（ItemCF + 向量召回 + 热门 + 关注）→ 合并去重 → 约 1000 个候选
        ↓
[排序阶段] → DeepFM / DIN 模型预测 CTR → 按 CTR × bid 加权排序 → Top 50
        ↓
[重排阶段] → 打散、多样性控制、业务规则（去重复、曝光控制等） → 最终展示约 20 条
```

### 补充：粗排（Pre-Ranking）

在召回和精排之间，大厂通常会多一层 **粗排**：

- 使用轻量模型（如浅层 DNN）从几千个召回结果中筛到几百个
- 目标是 **在保证效果的前提下，降低后续精排的计算量**，平衡效率与精度

---

## 1️⃣ 召回（Recall / Candidate Generation）

### 🎯 目标

从 **千万级甚至亿级的全量物品库**（商品、短视频、新闻等）中，
**快速、高效** 地筛出 *几百到几千个* 用户可能感兴趣的候选集合。

### ⚙️ 特点

| **维度**     | **说明**                                      |
|--------------|-----------------------------------------------|
| **速度要求** | 极高（通常 < 50ms）                           |
| **精度要求** | 相对宽松（宁可多召，不可严重漏掉潜在兴趣）   |
| **模型复杂度** | 模型相对简单、轻量（或使用近似检索）       |
| **输入特征** | 用户粗粒度画像 + 物品基础属性                |

### 🧠 常见召回方法

| **类型**           | **模型 / 算法举例**                                 |
|--------------------|------------------------------------------------------|
| 协同过滤           | UserCF, ItemCF                                      |
| 向量化召回（Embedding） | YouTube DNN、Airbnb Embedding 等             |
| 双塔模型（Two-Tower）  | DSSM、Facebook EBR、典型用户塔 / 物品塔结构   |
| 图召回             | PinSage, GraphSAGE 等图神经网络模型                |
| 多路召回（Multi-channel） | 热门召回、标签召回、向量召回、序列召回 等多策略融合 |

> 💡 实际工程中，召回阶段通常会 **并行跑多路召回策略**，然后对结果进行合并与去重，形成最终候选集。

---

## 2️⃣ 排序（Ranking / CTR 预估）

### 🎯 目标

对召回阶段返回的 **几百个候选物品**：

- 精准预测用户的 **点击率（CTR）**、**观看时长**、**转化率（CVR）** 等
- 按得分从高到低排序，取 **Top-N** 展示给用户

### ⚙️ 特点

| **维度**       | **说明**                                           |
|----------------|----------------------------------------------------|
| **速度要求**   | 较高（通常 < 100ms）                               |
| **精度要求**   | 极高（直接影响 CTR、留存、收入等核心指标）        |
| **模型复杂度** | 可以比较复杂（深度模型、多任务、序列建模等）      |
| **输入特征**   | 丰富的交叉特征（用户×物品、上下文、实时行为等）  |

### 🧠 常见排序模型

| **模型**          | **特点**                                     |
|-------------------|----------------------------------------------|
| LR + 特征工程     | 早期工业界主流，依赖大量人工特征交叉        |
| GBDT + LR         | Facebook 经典 CTR 方案                      |
| Wide & Deep       | Google 提出，兼顾“记忆”和“泛化能力”        |
| DeepFM            | 自动学习高阶特征交叉                         |
| DIN / DIEN        | 引入 **兴趣建模**，对行为序列做注意力加权   |
| MMoE / PLE        | 多任务学习（例如 CTR + CVR + 时长）          |
| Transformer / BST | 使用 Transformer 对行为序列进行深度建模     |

> ✅ **CTR 预估是排序阶段的核心任务**，但实际业务中也会同时优化 GMV、观看时长、互动率等复合目标。

---

## 3️⃣ 小结：召回 vs 排序

- **召回**：
  - 面对的是 **巨大的物品集合**（千万 / 亿级）
  - 核心是 **快速缩小候选空间**，多路召回、偏“粗粒度相关性”
  - 更关注 **召回率、覆盖率**，宁可多召一些“不那么准”的，也不能错过太多

- **排序**：
  - 面对的是 **召回后的少量候选**（几百 / 几千）
  - 核心是 **精细打分**，直接决定用户看到什么
  - 更关注 **精度指标**（AUC、NDCG、在线 CTR / 转化率）

在完整推荐系统里，两者是 **分工协作** 的关系：

1. 召回负责 "把可能感兴趣的都拉进来"；
2. 排序负责 "在这些里面挑出最可能点 / 看 / 买的"；
3. 重排 / 业务规则负责 "体验和业务目标的平衡"（多样性、新鲜度、控制广告比例等）。
